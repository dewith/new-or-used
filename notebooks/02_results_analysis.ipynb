{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Embeddings Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "Now that we have run the training flows, we can use Metaflow's Client API as a handy way to fetch results, analyze performance and decide how to iterate on embeddings, modeling approaches, and experiment design."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "First we import the packages we need and define some config variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "for _ in range(3):\n",
    "    if os.path.exists(f'{os.getcwd()}/setup.py'):\n",
    "        break\n",
    "    os.chdir('..')\n",
    "print('Current working directory:', os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from random import choice\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from metaflow import Flow\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "from src.utils.styling import apply_styling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = apply_styling()\n",
    "palette = colors['palette']\n",
    "\n",
    "FLOW_NAME = 'ModelingFlow'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "Let's retrieved the artifacts from the latest successful run. \n",
    "The `get_latest_successful_run` uses the `metaflow.Flow` object to get results of runs using the (class) name of the flows. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latest_successful_run(flow_name: str):\n",
    "    \"Gets the latest successful run.\"\n",
    "    for run in Flow(flow_name).runs():\n",
    "        if run.successful:\n",
    "            return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "latest_run = get_latest_successful_run(FLOW_NAME)\n",
    "latest_model = latest_run.data.final_vectors\n",
    "latest_dataset = latest_run.data.final_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "First, we check all is in order by printing out datasets and rows and stats:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(latest_dataset))\n",
    "latest_dataset.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Model vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "Now, let's turn our attention to the model - the embedding space we trained: let's check how big it is and use it to make a test prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Track vectors in the space: {}\".format(len(latest_model)))\n",
    "\n",
    "test_track = choice(list(latest_model.index_to_key))\n",
    "test_vector = latest_model[test_track]\n",
    "test_sims = latest_model.most_similar(test_track, topn=3)\n",
    "\n",
    "print(\"Example track: '{}'\".format(test_track))\n",
    "print(\"Test vector for '{}': {}\".format(test_track, test_vector[:5]))\n",
    "print(\"Similar songs to '{}': {}\".format(test_track, test_sims))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14",
   "metadata": {},
   "source": [
    "The skip-gram model we trained is an embedding space: if we did our job correctly, the space is such that tracks closer in the space are actually similar, and tracks that are far apart are pretty unrelated.\n",
    "\n",
    "[Judging the quality of \"fantastic embeddings\" is hard](https://arxiv.org/abs/2007.14906), but we point here to some common qualitative checks you can run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_track = 'Daft Punk-Get Lucky - Radio Edit'\n",
    "test_sims = latest_model.most_similar(test_track, topn=5)\n",
    "print(f\"Similar songs to '{test_track}':\")\n",
    "for song in test_sims:\n",
    "    print('  ',song[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "If you use 'Daft Punk|||Get Lucky - Radio Edit' as the query item in the space, you will discover a pretty interesting phenomenon, that is, that there are unfortunately many duplicates in the datasets, that is, songs which are technically different but semantically the same, i.e. Daft Punk|||Get Lucky - Radio Edit vs Daft Punk|||Get Lucky.\n",
    "\n",
    "This is a problem as\n",
    "\n",
    "i) working with dirty data may be misleading, and \n",
    "\n",
    "ii) these issues make data sparsity worse, so the task for our model is now harder. That said, it is cool that KNN can be used to quickly identify and potentially remove duplicates, depending on your dataset and use cases."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "Let's map some tracks to known categories: the intuition is that songs that are similar will be colored in the same way in the chart, and so we will expect them to be close in the embedding space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "track_sequence = latest_dataset['track_sequence'] \n",
    "songs = [item for sublist in track_sequence for item in sublist]\n",
    "song_counter = Counter(songs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "We downsample the vector space a bit to the K most common songs to avoid crowding the plot / analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOP_N_TRACKS = 1000\n",
    "top_tracks = [_[0] for _ in song_counter.most_common(TOP_N_TRACKS)]\n",
    "tracks = [_ for _ in latest_model.index_to_key if _ in top_tracks]\n",
    "print(tracks)\n",
    "\n",
    "# assert TOP_N_TRACKS == len(tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks_to_category = {t: 'unknown' for t in tracks}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "We tag songs based on keywords found in the playlist name. Of course, better heuristics are possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_playlists_names = set(\n",
    "    latest_dataset['playlist_id'].apply(lambda r: r.split('-')[1].lower().strip())\n",
    ")\n",
    "target_categories = [\n",
    "    'rock',\n",
    "    'rap',\n",
    "    'country'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24",
   "metadata": {},
   "source": [
    "This select the playlists with the target keyword, and mark the tracks as belonging to that category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_tracks_with_category(_df, target_word, tracks_to_category):\n",
    "    _df = _df[_df['playlist_id'].str.contains(target_word)]\n",
    "    # debug\n",
    "    print(len(_df))\n",
    "    # unnest the list\n",
    "    songs = [item for sublist in _df['track_sequence'] for item in sublist]\n",
    "    for song in songs:\n",
    "        if song in tracks_to_category and tracks_to_category[song] == 'unknown':\n",
    "            tracks_to_category[song] = target_word\n",
    "\n",
    "    return tracks_to_category\n",
    "\n",
    "\n",
    "for cat in target_categories:\n",
    "    print('Processing {}'.format(cat))\n",
    "    tracks_to_category = tag_tracks_with_category(\n",
    "        latest_dataset, cat, tracks_to_category\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "Note: to visualize a n-dimensional space, we need to be in 2D. We can use a dimensionality reduction technique like [TSNE](https://scikit-learn.org/stable/modules/generated/sklearn.manifold.TSNE.html) for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_analysis(embeddings, perplexity=50, n_iter=1000):\n",
    "    \"\"\"TSNE dimensionality reduction of track embeddings. It may take a while!.\"\"\"\n",
    "    return TSNE(\n",
    "        n_components=2,\n",
    "        perplexity=perplexity,\n",
    "        n_iter=n_iter,\n",
    "        verbose=1,\n",
    "        learning_rate='auto',\n",
    "        init='random',\n",
    "        random_state=42\n",
    "    ).fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add all the tagged tracks to the embedding space, on top of the popular tracks\n",
    "for track, cat in tracks_to_category.items():\n",
    "    # Add a track if we have a tag, if we have a vector for it\n",
    "    # and if not there already\n",
    "    if (\n",
    "        cat in target_categories\n",
    "        and track in latest_model.index_to_key\n",
    "        and track not in tracks\n",
    "    ):\n",
    "        tracks.append(track)\n",
    "\n",
    "print(len(tracks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract the vectors from the model and project them in 2D\n",
    "embeddings = np.array([latest_model[t] for t in tracks])\n",
    "# debug, print out embedding shape\n",
    "print(embeddings.shape)\n",
    "tsne_results = tsne_analysis(embeddings, perplexity=10, n_iter=5000)\n",
    "assert len(tsne_results) == len(tracks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "Now we can plot the 2D representations produced by the TSNE algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = {}\n",
    "for item, target_cat in tracks_to_category.items():\n",
    "    if item not in tracks:\n",
    "        continue\n",
    "\n",
    "    item_idx = tracks.index(item)\n",
    "    x = tsne_results[item_idx][0]\n",
    "    y = tsne_results[item_idx][1]\n",
    "    if target_cat in groups:\n",
    "        groups[target_cat]['x'].append(x)\n",
    "        groups[target_cat]['y'].append(y)\n",
    "    else:\n",
    "        groups[target_cat] = {'x': [x], 'y': [y]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "group_colors = {\n",
    "    'rock': palette[0],\n",
    "    'rap': palette[1],\n",
    "    'country': palette[2],\n",
    "    'unknown': colors['lines'],\n",
    "}\n",
    "for group, data in groups.items():\n",
    "    axs[0].scatter(\n",
    "        data['x'],\n",
    "        data['y'],\n",
    "        alpha=0.4 if group == 'unknown' else 0.8,\n",
    "        color=group_colors[group],\n",
    "        edgecolors='none',\n",
    "        s=25,\n",
    "        marker='o',\n",
    "        label=group,\n",
    "    )\n",
    "\n",
    "\n",
    "[axs[0].spines[dir].set_visible(False) for dir in ['top', 'bottom', 'left', 'right']]\n",
    "axs[0].set_title('Music in (latent) space')\n",
    "axs[0].set_ylabel('')\n",
    "axs[0].set_xlabel('')\n",
    "axs[0].set_xticks([])\n",
    "axs[0].set_yticks([])\n",
    "axs[0].legend(frameon=False)\n",
    "axs[1].axis('off')\n",
    "\n",
    "fig.tight_layout(pad=3.0)\n",
    "fig.savefig('data/06_viz/tsne_latent_space.png', bbox_inches='tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "a665b5d41d17b532ea9890333293a1b812fa0b73c9c25c950b3cedf1bebd0438"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
